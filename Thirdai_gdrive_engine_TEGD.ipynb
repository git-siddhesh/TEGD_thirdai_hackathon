{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-siddhesh/TEGD_thirdai_hackathon/blob/main/Thirdai_gdrive_engine_TEGD.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnIfQGtUNKD9",
        "outputId": "d9eef788-4895-45b4-e546-c14d15c2fa39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9bciBRkbnA9"
      },
      "outputs": [],
      "source": [
        "root_directory = '/content/drive/MyDrive'\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN8BOj1w10bB"
      },
      "outputs": [],
      "source": [
        "loc_map_dict = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZYml3a957k"
      },
      "source": [
        "## Fetch All the Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO8KjW4ubwYq"
      },
      "outputs": [],
      "source": [
        "# Walk through all directories and subdirectories\n",
        "from collections import defaultdict\n",
        "\n",
        "all_files = defaultdict(list)\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
        "    # print(f\"Current directory: {dirpath}\")\n",
        "\n",
        "    # List the files in the current directory\n",
        "    for filename in filenames:\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "        # print(f\"File: {file_path}\")\n",
        "        file_type = file_path.split('.')[-1]\n",
        "        all_files[file_type].append(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2K8HqTNcGWM",
        "outputId": "c57b0229-801d-4e76-94bb-899dd05ea6fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['pdf', 'docx', 'zip', 'gdoc', 'jpeg', 'ipynb', 'jpg', 'm', 'gslides', 'webp', 'xlsx', 'py', 'pptx', 'csv', 'gsheet', 'fig', 'wav', 'txt', 'pkl', 'mp3'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_files.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvrkrTT5ehDO",
        "outputId": "5a13d615-3f31-40d4-f632-6fdb4b262280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file type: pdf has 17 files\n",
            "file type: mp3 has 23 files\n",
            "file type: docx has 14 files\n"
          ]
        }
      ],
      "source": [
        "for file_ext in ['pdf', 'mp3', 'docx']:\n",
        "    print(f\"file type: {file_ext} has {len(all_files[file_ext])} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGxMxLbNfjEK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO2JVKbpyzRu"
      },
      "source": [
        "### Extract the text from mp3 file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PIo7-UszbdS"
      },
      "source": [
        "#### Gather the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3s07Alh-E63",
        "outputId": "93006227-31f4-46fa-d484-a89b20e76063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to fetch and train mp3 files too?\n",
            "It will take a lot of time. We can skip it for now\n"
          ]
        }
      ],
      "source": [
        "mp3_train = False\n",
        "print(\"Do you want to fetch and train mp3 files too?\")\n",
        "print(\"It will take a lot of time. We can skip it for now\")\n",
        "# if 'y' in input(\"Press 'y' to extract audio files else press 'n'\").lower():\n",
        "#   mp3_train = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTYVvn8-8ao",
        "outputId": "384948b1-0941-4495-e533-a800e7f99d20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mp3_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZMPQp8LylLy",
        "outputId": "62bcc8f3-d1fb-4cec-9fef-3c415cc98b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You need to install all the dependencies later\n"
          ]
        }
      ],
      "source": [
        "if mp3_train:\n",
        "  !git clone https://github.com/ggerganov/whisper.cpp.git\n",
        "  %cd /content/whisper.cpp/models\n",
        "  !bash download-ggml-model.sh base.en\n",
        "  %cd ..\n",
        "  !make\n",
        "  !pip install pydub\n",
        "  !apt install ffmpeg\n",
        "  from pydub import AudioSegment\n",
        "\n",
        "else:\n",
        "  print(\"You need to install all the dependencies later\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRfOGSqhhNYO"
      },
      "source": [
        "```python  \n",
        "\n",
        "!git clone https://github.com/ggerganov/whisper.cpp.git  \n",
        "%cd /content/whisper.cpp/models  \n",
        "!bash download-ggml-model.sh base.en  \n",
        "%cd ..  \n",
        "!make   \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cCk1QrQyovz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuRey2MpzTfT"
      },
      "source": [
        "```python  \n",
        "!pip install pydub  \n",
        "!apt install ffmpeg  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af1S5cnTz05p"
      },
      "source": [
        "#### UTILS functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lGYMmq-z8wB"
      },
      "source": [
        "> Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwhNirUIzwQs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0p8qd-ez_1O"
      },
      "source": [
        "> mp3 -> wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvt1xgs6z8JN"
      },
      "outputs": [],
      "source": [
        "def convert_to_wav(file_path, audio_log_dir):\n",
        "    # Split the file path into base and extension\n",
        "    base, ext = os.path.splitext(file_path)\n",
        "    # Only process files that aren't already in wav format\n",
        "    if ext.lower() != \".wav\":\n",
        "        # Load the audio file\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        # Set frame rate to 16 kHz\n",
        "        audio = audio.set_frame_rate(16000)\n",
        "        # Save as wav\n",
        "        wav_file_path = audio_log_dir + base.split('/')[-1] + \".wav\"\n",
        "        audio.export(wav_file_path, format=\"wav\")\n",
        "        print(f\"Saved as {wav_file_path}\")\n",
        "    else:\n",
        "        print(f\"File is already in wav format: {file_path}\")\n",
        "    return wav_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5wH0wJu0JO1"
      },
      "source": [
        "> wav -> text (using whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMQfoI90IZW"
      },
      "outputs": [],
      "source": [
        "def transcript_wav_totext_using_whisper(wav_file_path):\n",
        "    base, ext = os.path.splitext(wav_file_path)\n",
        "    command = f\"./main -f '{wav_file_path}' >  {base}.txt\"\n",
        "    print(command)\n",
        "    process = subprocess.run(command, shell=True, check=True)\n",
        "    text_file_path = f'{base}.txt'\n",
        "    return text_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1z8a81U0h7F"
      },
      "source": [
        "> text -> csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUzs6Zbw0T5m"
      },
      "outputs": [],
      "source": [
        "def generate_transcription_csv(text_file_path):\n",
        "    csv_file_path = text_file_path.replace('.txt', '.csv')\n",
        "    with open(text_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "        for line in txt_file:\n",
        "            line = line.strip()\n",
        "            # Skip empty lines\n",
        "            if line == '':\n",
        "                continue\n",
        "            # Split the line into timestamp and transcription\n",
        "            time_stamp, transcription = line.split(']', 1)\n",
        "            # Remove the leading '[' from the timestamp\n",
        "            time_stamp = time_stamp[1:]\n",
        "            # Remove leading and trailing spaces from the transcription\n",
        "            transcription = transcription.strip()\n",
        "            # Skip lines where the transcription is enclosed in square brackets\n",
        "            if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "                # Write the data to the CSV file\n",
        "                csv_writer.writerow([time_stamp, transcription])\n",
        "    print(f\"CSV file has been saved at: {csv_file_path}\")\n",
        "    return csv_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IszB7Gqp0pxz"
      },
      "source": [
        "#### **Final** call: mp3 -> *csv*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r813fCy_9yoj"
      },
      "outputs": [],
      "source": [
        "def begin(file_path, audio_log_dir):\n",
        "    wav_file_path = convert_to_wav(file_path, audio_log_dir)\n",
        "    #################### Map The original path of the mp3 file to csv file ##############\n",
        "    text_file_path = transcript_wav_totext_using_whisper(wav_file_path)\n",
        "    csv_file_path = generate_transcription_csv(text_file_path)\n",
        "    loc_map_dict[csv_file_path] = file_path\n",
        "    print(f'file_path {file_path}')\n",
        "    print(f'wav_file_path {wav_file_path}')\n",
        "    print(f'text_file_path {text_file_path}\\n')\n",
        "    print(f\"File {file_path} converted to csv {text_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNHyn_uk0hO5"
      },
      "outputs": [],
      "source": [
        "\n",
        "if mp3_train:\n",
        "  print(root_directory)\n",
        "  os.chdir(root_directory)\n",
        "  !pwd\n",
        "  audio_log_dir = root_directory+\"/log_dir/audio_csv/\"\n",
        "  if not os.path.exists(audio_log_dir):\n",
        "      print(\"Create audio log dir\")\n",
        "      os.makedirs('log_dir/audio_csv')\n",
        "\n",
        "  else:\n",
        "      print(\"path already exist\",audio_log_dir)\n",
        "\n",
        "  os.chdir('/content/whisper.cpp/')\n",
        "  for mp3_file in all_files['mp3']:\n",
        "      begin(mp3_file, audio_log_dir)\n",
        "      break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osH7I1rHBCI7",
        "outputId": "9a0f4bc1-469b-4555-a467-ded087b2dfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loc_map_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_itp7scT_Du2"
      },
      "source": [
        "## Train Neural DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csLA1-G1_MQI"
      },
      "source": [
        "> imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URMyppf7_lmo"
      },
      "source": [
        "\n",
        "```python\n",
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2njVmxru_p4a",
        "outputId": "539260d9-8af3-477f-f07d-1cb8744b076a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyTrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install thirdai --upgrade -q\n",
        "!pip3 install thirdai[neural_db] -q\n",
        "!pip3 install langchain --upgrade -q\n",
        "!pip3 install openai --upgrade -q\n",
        "!pip3 install paper-qa --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zMGIAzf-_3A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from thirdai import licensing, neural_db as ndb\n",
        "licensing.deactivate()\n",
        "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W5vEbvaAMWX"
      },
      "outputs": [],
      "source": [
        "db = ndb.NeuralDB(user_id=\"siddhesh_saiKrishna\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dk1hmdUaAdFn",
        "outputId": "7b4bead4-7eb0-42fb-b22b-36a34d5cc898"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(\"/content\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrzB0DhLAjqo"
      },
      "outputs": [],
      "source": [
        "# Set up a cache directory\n",
        "import os\n",
        "if not os.path.isdir(\"bazaar_cache\"):\n",
        "    os.mkdir(\"bazaar_cache\")\n",
        "from pathlib import Path\n",
        "from thirdai.neural_db import Bazaar\n",
        "bazaar = Bazaar(cache_dir=Path(\"bazaar_cache\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAwiVxEBA0nW"
      },
      "outputs": [],
      "source": [
        "bazaar.fetch() # Optional arg filter=\"model name\" to filter by model name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc5IjrO9A3Tx",
        "outputId": "f02a9fd9-dbe3-4b69-c5d8-e7bc6ba4e8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Contract Review', 'Finance QnA', 'General QnA']\n"
          ]
        }
      ],
      "source": [
        "print(bazaar.list_model_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yzKpUTtA7gx"
      },
      "outputs": [],
      "source": [
        "db = bazaar.get_model(\"General QnA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1kuoIuNBZvr"
      },
      "source": [
        "## Insert files to N-DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69d6QmjWB0_t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEl3AEizB0wK",
        "outputId": "f4645706-d7e2-4fdf-877a-7030bace5791"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSqlUHb9BhvA"
      },
      "source": [
        "#### PDFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_8TJxF1BgyA",
        "outputId": "d461ca8e-c198-4bb0-b2a7-e4785b08d6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/22210045_A1.pdf done\n",
            "/content/drive/MyDrive/22210045_AI.pdf done\n",
            "/content/drive/MyDrive/22210045_expert.pdf done\n",
            "/content/drive/MyDrive/22210045_general.pdf done\n",
            "/content/drive/MyDrive/Edited - exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/CCL Tennis Teams List - Sheet2.pdf done\n",
            "/content/drive/MyDrive/PARAM Ananta User Guide 1.1.pdf done\n",
            "/content/drive/MyDrive/Tut_1_SiddhiRahpurohit_.pdf done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/22210045_journal3.pdf done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/22210045_journal_4.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_ (2).pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/Edited - exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/Computation neuroscience.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_examinatio_3pptx.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_ (1).pdf done\n"
          ]
        }
      ],
      "source": [
        "insertable_docs = []\n",
        "pdf_files = all_files['pdf']\n",
        "\n",
        "for file in pdf_files:\n",
        "    try:\n",
        "        pdf_doc = ndb.PDF(file)\n",
        "        insertable_docs.append(pdf_doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCF_Ae5vINQ4"
      },
      "source": [
        "#### docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvuAU4NDj-v",
        "outputId": "2ae47104-92ab-462d-d055-09fd74bb409a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/22210045_AI.docx done\n",
            "/content/drive/MyDrive/22210045_Assignment1.docx done\n",
            "/content/drive/MyDrive/22210045_A1.docx done\n",
            "/content/drive/MyDrive/22210045_A2.docx done\n",
            "/content/drive/MyDrive/22210045_Assignment_3 (1).docx done\n",
            "/content/drive/MyDrive/22210045_Assignment_3.docx done\n",
            "/content/drive/MyDrive/HSS_WCC_2 (1).docx done\n",
            "/content/drive/MyDrive/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Do's and Don't AC in hostels.docx done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/HSS_history.docx done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Classroom/Plag sid 1/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Classroom/check-suraj/HSS_WCC_2 (1).docx done\n",
            "/content/drive/MyDrive/Classroom/check-suraj/HSS_WCC_2.docx done\n"
          ]
        }
      ],
      "source": [
        "doc_files = all_files['docx']\n",
        "\n",
        "for file in doc_files:\n",
        "    try:\n",
        "        doc = ndb.DOCX(file)\n",
        "        insertable_docs.append(doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3DAwre73Tw2",
        "outputId": "800cb23e-c05b-4b3d-a3b4-c8e8e87af3ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys([])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loc_map_dict.keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akUqXpxfIPVd"
      },
      "source": [
        "#### music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jy9KBbg30ip"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZWEnclx49uV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y28oJk8C5m-i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE2kknBQIKS5"
      },
      "outputs": [],
      "source": [
        "if mp3_train:\n",
        "    audio_files = [audio_log_dir+file for file in os.listdir(audio_log_dir) if file.endswith('.csv')]\n",
        "    for file in audio_files:\n",
        "        df = pd.read_csv(file)\n",
        "        # Add the new column with values from 0 to n-1\n",
        "        df['DOC_ID'] = range(len(df))\n",
        "        # Save the updated DataFrame back to the CSV file\n",
        "        df.to_csv(file, index=False)\n",
        "    for file in audio_files:\n",
        "        try:\n",
        "            csv_doc = ndb.CSV(\n",
        "                path=file,\n",
        "                id_column=\"DOC_ID\",\n",
        "                strong_columns=[\"transcription\"],\n",
        "                weak_columns=[\"time_stamp\"],\n",
        "                reference_columns=[\"time_stamp\"])\n",
        "            insertable_docs.append(csv_doc)\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YrCU3zgISNV"
      },
      "source": [
        "### Insert into database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKR1bvMOFAhj"
      },
      "outputs": [],
      "source": [
        "source_ids = db.insert(insertable_docs, train=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPa1lItJGKkc"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cxiq3CmGLkj",
        "outputId": "5a53c164-18fd-4444-b42b-56c8be76c9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter prompt: System Architecture and Configuration 8 S\n",
            "------------------ TOP 1 result -----------------------\n",
            "PARAM Ananta - User's Manual Page | 8 System Architecture and Configuration System Hardware Specifications PARAM Ananta system is based on processor Intel Xeon Platinum 8268 and Intel Xeon Gold 6248 and with total peak performance of 838 TFLOPS. The cluster consists of compute nodes connected with BullSequana XH2000 HDR 100 InfiniBand interconnect network. The system uses the Lustre parallel file system.\n",
            "______ SOURCE _________\n",
            "/content/drive/MyDrive/PARAM Ananta User Guide 1.1.pdf\n",
            "--------------------------------------------------\n",
            "------------------ TOP 2 result -----------------------\n",
            "__COMPARISION WITH OTHER WORK__ Comparison of architecture A comparison of architecture and input choices across studies using the publicly available DEAP [56] dataset. The table shows study effectiveness as accuracy increases moving down the table.\n",
            "______ SOURCE _________\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_examinatio_3pptx.pdf\n",
            "--------------------------------------------------\n",
            "------------------ TOP 3 result -----------------------\n",
            "Used a Muse EEG headband which recorded the TP9 AF7 AF8 and TP10 EEG placements via dry electrodes. Six minutes of resting neutral data are also recorded the stimuli used to evoke the emotions are below [6] [7] 2.4 Dataset Processing and Feature extraction 2.5 Implementations Machine learning Algorithms These methods include linear discriminant analysis (LDA) Naive Bayes (NB) support vector machine (SVM) random for- est (RF) k-nearest neighbors (k-NN) multiple layer perception (MLP) and others.\n",
            "______ SOURCE _________\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_.pdf\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query = input(\"Enter prompt: \")\n",
        "search_results = db.search(\n",
        "    # query=\"what is the termination period\",\n",
        "    query=query,\n",
        "    top_k=3,\n",
        "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
        "\n",
        "for i, result in enumerate(search_results):\n",
        "    print(f\"------------------ TOP {i+1} result -----------------------\")\n",
        "    print(result.text)\n",
        "    # print(result.context(radius=1))\n",
        "    print(\"______ SOURCE _________\")\n",
        "    if loc_map_dict.get(result.source, None) == None:\n",
        "        print(result.source)\n",
        "    else:\n",
        "        print(loc_map_dict.get(result.source, None))\n",
        "    # print(result.metadata)\n",
        "    print(\"--------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TUThFZqHwkh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
