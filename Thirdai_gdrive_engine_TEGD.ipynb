{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnIfQGtUNKD9",
        "outputId": "7f02096e-dcb2-4065-c853-c1ea147f9b59"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_directory = '/content/drive/MyDrive'\n",
        "import os\n"
      ],
      "metadata": {
        "id": "Z9bciBRkbnA9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loc_map_dict = dict()"
      ],
      "metadata": {
        "id": "JN8BOj1w10bB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through all directories and subdirectories\n",
        "from collections import defaultdict\n",
        "\n",
        "all_files = defaultdict(list)\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
        "    print(f\"Current directory: {dirpath}\")\n",
        "\n",
        "    # List the files in the current directory\n",
        "    for filename in filenames:\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "        # print(f\"File: {file_path}\")\n",
        "        file_type = file_path.split('.')[-1]\n",
        "        all_files[file_type].append(file_path)\n"
      ],
      "metadata": {
        "id": "MO8KjW4ubwYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_files.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2K8HqTNcGWM",
        "outputId": "3a5397d1-70ff-459d-b042-d051afec4420"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['pdf', 'docx', 'zip', 'gdoc', 'jpeg', 'ipynb', 'jpg', 'm', 'gslides', 'webp', 'xlsx', 'py', 'pptx', 'csv', 'gsheet', 'fig', 'pkl', 'mp3'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_ext in ['pdf', 'mp3', 'docx']:\n",
        "    print(f\"file type: {file_ext} has {len(all_files[file_ext])} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvrkrTT5ehDO",
        "outputId": "d961579c-da1f-455c-eba4-cae3c46a3047"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file type: pdf has 80 files\n",
            "file type: mp3 has 24 files\n",
            "file type: docx has 14 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGxMxLbNfjEK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the text from mp3 file"
      ],
      "metadata": {
        "id": "wO2JVKbpyzRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gather the requirements"
      ],
      "metadata": {
        "id": "2PIo7-UszbdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python  \n",
        "\n",
        "!git clone https://github.com/ggerganov/whisper.cpp.git  \n",
        "%cd /content/whisper.cpp/models  \n",
        "!bash download-ggml-model.sh base.en  \n",
        "%cd ..  \n",
        "!make   \n",
        "```"
      ],
      "metadata": {
        "id": "pRfOGSqhhNYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python  \n",
        "!pip install pydub  \n",
        "!apt install ffmpeg  \n",
        "```"
      ],
      "metadata": {
        "id": "LuRey2MpzTfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UTILS functions"
      ],
      "metadata": {
        "id": "Af1S5cnTz05p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Imports"
      ],
      "metadata": {
        "id": "0lGYMmq-z8wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import csv\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "bwhNirUIzwQs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> mp3 -> wav"
      ],
      "metadata": {
        "id": "K0p8qd-ez_1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_wav(file_path, audio_log_dir):\n",
        "    # Split the file path into base and extension\n",
        "    base, ext = os.path.splitext(file_path)\n",
        "    # Only process files that aren't already in wav format\n",
        "    if ext.lower() != \".wav\":\n",
        "        # Load the audio file\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        # Set frame rate to 16 kHz\n",
        "        audio = audio.set_frame_rate(16000)\n",
        "        # Save as wav\n",
        "        wav_file_path = audio_log_dir + base.split('/')[-1] + \".wav\"\n",
        "        audio.export(wav_file_path, format=\"wav\")\n",
        "        print(f\"Saved as {wav_file_path}\")\n",
        "    else:\n",
        "        print(f\"File is already in wav format: {file_path}\")\n",
        "    return wav_file_path"
      ],
      "metadata": {
        "id": "yvt1xgs6z8JN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> wav -> text (using whisper)"
      ],
      "metadata": {
        "id": "_5wH0wJu0JO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcript_wav_totext_using_whisper(wav_file_path):\n",
        "    base, ext = os.path.splitext(wav_file_path)\n",
        "    command = f\"./main -f '{wav_file_path}' >  {base}.txt\"\n",
        "    print(command)\n",
        "    process = subprocess.run(command, shell=True, check=True)\n",
        "    text_file_path = f'{base}.txt'\n",
        "    return text_file_path"
      ],
      "metadata": {
        "id": "eZMQfoI90IZW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> text -> csv"
      ],
      "metadata": {
        "id": "w1z8a81U0h7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transcription_csv(text_file_path):\n",
        "    csv_file_path = text_file_path.replace('.txt', '.csv')\n",
        "    with open(text_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "        for line in txt_file:\n",
        "            line = line.strip()\n",
        "            # Skip empty lines\n",
        "            if line == '':\n",
        "                continue\n",
        "            # Split the line into timestamp and transcription\n",
        "            time_stamp, transcription = line.split(']', 1)\n",
        "            # Remove the leading '[' from the timestamp\n",
        "            time_stamp = time_stamp[1:]\n",
        "            # Remove leading and trailing spaces from the transcription\n",
        "            transcription = transcription.strip()\n",
        "            # Skip lines where the transcription is enclosed in square brackets\n",
        "            if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "                # Write the data to the CSV file\n",
        "                csv_writer.writerow([time_stamp, transcription])\n",
        "    print(f\"CSV file has been saved at: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "zUzs6Zbw0T5m"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Final** call: mp3 -> *csv*"
      ],
      "metadata": {
        "id": "IszB7Gqp0pxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def begin(file_path, audio_log_dir):\n",
        "    wav_file_path = convert_to_wav(file_path, audio_log_dir)\n",
        "    #################### Map The original path of the mp3 file to csv file ##############\n",
        "    text_file_path = transcript_wav_totext_using_whisper(wav_file_path)\n",
        "    generate_transcription_csv(text_file_path)\n",
        "    loc_map_dict[text_file_path] = file_path\n",
        "    print(f'file_path {file_path}')\n",
        "    print(f'wav_file_path {wav_file_path}')\n",
        "    print(f'text_file_path {text_file_path}\\n')\n",
        "    print(f\"File {file_path} converted to csv {text_file_path}\")\n",
        "\n",
        "print(root_directory)\n",
        "os.chdir(root_directory)\n",
        "!pwd\n",
        "audio_log_dir = root_directory+\"/log_dir/audio_csv/\"\n",
        "if not os.path.exists(audio_log_dir):\n",
        "    print(\"Create audio log dir\")\n",
        "    os.makedirs('log_dir/audio_csv')\n",
        "\n",
        "else:\n",
        "    print(\"path already exist\",audio_log_dir)\n",
        "\n",
        "os.chdir('/content/whisper.cpp/')\n",
        "for mp3_file in all_files['mp3']:\n",
        "    begin(mp3_file, audio_log_dir)\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNHyn_uk0hO5",
        "outputId": "baf63750-973d-4e9e-873e-dcc038b91e83"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive\n",
            "path already exist /content/drive/MyDrive/log_dir/audio_csv/\n",
            "Saved as /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.wav\n",
            "./main -f '/content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.wav' >  /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.txt\n",
            "CSV file has been saved at: /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.csv\n",
            "file_path /content/drive/MyDrive/thirdai_hack/road_to_oz_64kb_mp3/roadtoOz_18_baum_64kb.mp3\n",
            "wav_file_path /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.wav\n",
            "text_file_path /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.txt\n",
            "\n",
            "File /content/drive/MyDrive/thirdai_hack/road_to_oz_64kb_mp3/roadtoOz_18_baum_64kb.mp3 converted to csv /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loc_map_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osH7I1rHBCI7",
        "outputId": "5228ddea-cf05-4ebd-ef59-e260ac3ff7be"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/drive/MyDrive/log_dir/audio_csvroadtoOz_18_baum_64kb.wav': '/content/drive/MyDrive/thirdai_hack/road_to_oz_64kb_mp3/roadtoOz_18_baum_64kb.mp3',\n",
              " '/content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.wav': '/content/drive/MyDrive/thirdai_hack/road_to_oz_64kb_mp3/roadtoOz_18_baum_64kb.mp3'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Neural DB"
      ],
      "metadata": {
        "id": "_itp7scT_Du2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> imports"
      ],
      "metadata": {
        "id": "csLA1-G1_MQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade\n",
        "```"
      ],
      "metadata": {
        "id": "URMyppf7_lmo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2njVmxru_p4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from thirdai import licensing, neural_db as ndb\n",
        "licensing.deactivate()\n",
        "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
      ],
      "metadata": {
        "id": "4zMGIAzf-_3A"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = ndb.NeuralDB(user_id=\"siddhesh_saiKrishna\")\n",
        ""
      ],
      "metadata": {
        "id": "5W5vEbvaAMWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dk1hmdUaAdFn",
        "outputId": "db784f10-2173-4ba7-df32-757bdbf6ff41"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a cache directory\n",
        "import os\n",
        "if not os.path.isdir(\"bazaar_cache\"):\n",
        "    os.mkdir(\"bazaar_cache\")\n",
        "from pathlib import Path\n",
        "from thirdai.neural_db import Bazaar\n",
        "bazaar = Bazaar(cache_dir=Path(\"bazaar_cache\"))"
      ],
      "metadata": {
        "id": "RrzB0DhLAjqo"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bazaar.fetch() # Optional arg filter=\"model name\" to filter by model name."
      ],
      "metadata": {
        "id": "YAwiVxEBA0nW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bazaar.list_model_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc5IjrO9A3Tx",
        "outputId": "8c62e44d-205f-47bc-831c-117a08f8abc2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Contract Review', 'Finance QnA', 'General QnA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = bazaar.get_model(\"General QnA\")"
      ],
      "metadata": {
        "id": "2yzKpUTtA7gx"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert files to N-DB"
      ],
      "metadata": {
        "id": "I1kuoIuNBZvr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69d6QmjWB0_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEl3AEizB0wK",
        "outputId": "8732d4af-b54a-4299-bb26-311d819e3f16"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PDFS"
      ],
      "metadata": {
        "id": "YSqlUHb9BhvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insertable_docs = []\n",
        "pdf_files = all_files['pdf']\n",
        "\n",
        "for file in pdf_files:\n",
        "    try:\n",
        "        pdf_doc = ndb.PDF(file)\n",
        "        insertable_docs.append(pdf_doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_8TJxF1BgyA",
        "outputId": "53b4be89-d90c-4ae8-de0d-83087ab7affc"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/22210045_A1.pdf done\n",
            "/content/drive/MyDrive/22210045_AI.pdf done\n",
            "/content/drive/MyDrive/22210045_expert.pdf done\n",
            "/content/drive/MyDrive/22210045_general.pdf done\n",
            "/content/drive/MyDrive/Edited - exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/CCL Tennis Teams List - Sheet2.pdf done\n",
            "/content/drive/MyDrive/PARAM Ananta User Guide 1.1.pdf done\n",
            "/content/drive/MyDrive/Tut_1_SiddhiRahpurohit_.pdf done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/22210045_journal3.pdf done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/22210045_journal_4.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_ (2).pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/Edited - exam_1_siddhesh_22210045.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/Computation neuroscience.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_examinatio_3pptx.pdf done\n",
            "/content/drive/MyDrive/Classroom/Computational Neuroscience 2023/22210045_project_comp_neuro__Copy_ (1).pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/The-Call-of-Cthulhu.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/At-the-Mountains-of-Madness.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/The-Yellow-Wallpaper.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/How-to-Sing.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/Life-of-Beethoven.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/A-Princess-of-Mars.pdf done\n",
            "cannot open empty document\n",
            "/content/drive/MyDrive/thirdai_hack/books/UnderstandingDeepLearning_26_07_23_C.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/UnderstandingDeepLearning_26_07_23_C (1).pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/1. Effective Study Techniques Author University of Otago.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/5. Habits of Mind Author Arthur L Costa.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl114.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh205.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leca102.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy102.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl111.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl106.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh207.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leca101.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh203.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl1ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech203.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech201.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech204.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy101.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech202.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl101.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leca1ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leca103.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl115.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl107.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech2ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech2an.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy103.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leca104.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl102.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl113.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl105.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh202.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh201.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh2ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lech205.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy107.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl103.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy1a1.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy104.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh206.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy108.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy106.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl112.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl108.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh2an.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy105.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lefl104.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps102.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/lemh204.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps101.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/legy1ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps106.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps105.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps1ps.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps104.pdf done\n",
            "/content/drive/MyDrive/thirdai_hack/books/leps103.pdf done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### docx"
      ],
      "metadata": {
        "id": "mCF_Ae5vINQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_files = all_files['docx']\n",
        "\n",
        "for file in doc_files:\n",
        "    try:\n",
        "        doc = ndb.DOCX(file)\n",
        "        insertable_docs.append(doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvuAU4NDj-v",
        "outputId": "fefc9927-cb4a-4d91-9932-bbd0ea91c14d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/22210045_AI.docx done\n",
            "/content/drive/MyDrive/22210045_Assignment1.docx done\n",
            "/content/drive/MyDrive/22210045_A1.docx done\n",
            "/content/drive/MyDrive/22210045_A2.docx done\n",
            "/content/drive/MyDrive/22210045_Assignment_3 (1).docx done\n",
            "/content/drive/MyDrive/22210045_Assignment_3.docx done\n",
            "/content/drive/MyDrive/HSS_WCC_2 (1).docx done\n",
            "/content/drive/MyDrive/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Do's and Don't AC in hostels.docx done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/HSS_history.docx done\n",
            "/content/drive/MyDrive/Classroom/HS 201 World Civilisations Journal Writing/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Classroom/Plag sid 1/HSS_WCC_2.docx done\n",
            "/content/drive/MyDrive/Classroom/check-suraj/HSS_WCC_2 (1).docx done\n",
            "/content/drive/MyDrive/Classroom/check-suraj/HSS_WCC_2.docx done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### music"
      ],
      "metadata": {
        "id": "akUqXpxfIPVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files = loc_map_dict.keys()\n",
        "\n",
        "for file in audio_files:\n",
        "    try:\n",
        "        doc = ndb.DOCX(file)\n",
        "        insertable_docs.append(doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        print(f\"could not insert {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2kknBQIKS5",
        "outputId": "a4ba2dba-c78d-4a07-83ed-c9027d4b7117"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could not insert /content/drive/MyDrive/log_dir/audio_csvroadtoOz_18_baum_64kb.wav\n",
            "could not insert /content/drive/MyDrive/log_dir/audio_csv/roadtoOz_18_baum_64kb.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### urls"
      ],
      "metadata": {
        "id": "_YrCU3zgISNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# valid_url_data = ndb.parsing_utils.recursive_url_scrape(base_url=\"https://www.thirdai.com/pocketllm/\", max_crawl_depth=0)\n",
        "# insertable_docs = []\n",
        "\n",
        "# for url, response in valid_url_data:\n",
        "#     try:\n",
        "#         insertable_docs.append(ndb.URL(url, response))\n",
        "#     except:\n",
        "#         continue"
      ],
      "metadata": {
        "id": "qOLYgxP8EXXY"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_ids = db.insert(insertable_docs, train=False)\n"
      ],
      "metadata": {
        "id": "jKR1bvMOFAhj"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search"
      ],
      "metadata": {
        "id": "yPa1lItJGKkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter prompt: \")\n",
        "search_results = db.search(\n",
        "    # query=\"what is the termination period\",\n",
        "    query=query,\n",
        "    top_k=3,\n",
        "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
        "\n",
        "for result in search_results:\n",
        "    print(result.text)\n",
        "    # print(result.context(radius=1))\n",
        "    if loc_map_dict.get(result.source, None) == None:\n",
        "        print(result.source)\n",
        "    else:\n",
        "        print(loc_map_dict.get(result.source, None))\n",
        "    # print(result.metadata)\n",
        "    print('************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cxiq3CmGLkj",
        "outputId": "cb1d98a4-bad0-4c34-c4ce-ef28d79d4cc2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter prompt: Niemann. What do you do, then, when you are hoarse? I. Oh, I practise and see whether it still troubles me. Niem. Indeed; and what do you practise? I. Long, slow scales. Niem. Even if you are hoarse? I. Yes; if I want to sing, or have to, I try it. Niem. Well, what are they? Show me. The great scale, the infallible cure.\n",
            "Thetrueartofsonghasalwaysbeenpossessedandwillalwaysbepossessedby suchindividualsasaredoweredbynaturewithallthatisneedfulforit--thatis healthyvocalorgans uninjuredbyvicioushabitsofspeech;agoodear atalent forsinging intelligence industry andenergy. Informertimeseightyearsweredevotedtothestudyofsinging--atthePrague Conservatory forinstance.Mostofthemistakesandmisunderstandingsofthe pupil could be discovered before he secured an engagement  and the teacher could spend so much time in correcting them that the pupil learned to pass judgmentonhimselfproperly.\n",
            "/content/drive/MyDrive/thirdai_hack/books/How-to-Sing.pdf\n",
            "************\n",
            "1.E.7.Donotchargeafeeforaccessto viewing displaying performing copyingordistributinganyProjectGutenberg-tmworks unlessyoucomplywithparagraph1.E.8or1.E.9. 1.E.8.Youmaychargeareasonablefeeforcopiesoforproviding accesstoordistributingProjectGutenberg-tmelectronicworksprovided that -Youpayaroyaltyfeeof20%ofthegrossprofitsyouderivefrom theuseofProjectGutenberg-tmworkscalculatedusingthemethod youalreadyusetocalculateyourapplicabletaxes.Thefeeis owedtotheowneroftheProjectGutenberg-tmtrademark buthe hasagreedtodonateroyaltiesunderthisparagraphtothe ProjectGutenbergLiteraryArchiveFoundation.Royaltypayments mustbepaidwithin60daysfollowingeachdateonwhichyou prepare(orarelegallyrequiredtoprepare)yourperiodictax returns.Royaltypaymentsshouldbeclearlymarkedassuchand senttotheProjectGutenbergLiteraryArchiveFoundationatthe addressspecifiedinSection4 \"Informationaboutdonationsto theProjectGutenbergLiteraryArchiveFoundation.\" -Youprovideafullrefundofanymoneypaidbyauserwhonotifies youinwriting(orbye-mail)within30daysofreceiptthats/he doesnotagreetothetermsofthefullProjectGutenberg-tm License.Youmustrequiresuchausertoreturnor destroyallcopiesoftheworkspossessedinaphysicalmedium anddiscontinuealluseofandallaccesstoothercopiesof ProjectGutenberg-tmworks.\n",
            "/content/drive/MyDrive/thirdai_hack/books/How-to-Sing.pdf\n",
            "************\n",
            "1.E.7.Donotchargeafeeforaccessto viewing displaying performing copyingordistributinganyProjectGutenberg-tmworks unlessyoucomplywithparagraph1.E.8or1.E.9. 1.E.8.Youmaychargeareasonablefeeforcopiesoforproviding accesstoordistributingProjectGutenberg-tmelectronicworksprovided that -Youpayaroyaltyfeeof20%ofthegrossprofitsyouderivefrom theuseofProjectGutenberg-tmworkscalculatedusingthemethod youalreadyusetocalculateyourapplicabletaxes.Thefeeis owedtotheowneroftheProjectGutenberg-tmtrademark buthe hasagreedtodonateroyaltiesunderthisparagraphtothe ProjectGutenbergLiteraryArchiveFoundation.Royaltypayments mustbepaidwithin60daysfollowingeachdateonwhichyou prepare(orarelegallyrequiredtoprepare)yourperiodictax returns.Royaltypaymentsshouldbeclearlymarkedassuchand senttotheProjectGutenbergLiteraryArchiveFoundationatthe addressspecifiedinSection4 \"Informationaboutdonationsto theProjectGutenbergLiteraryArchiveFoundation.\" -Youprovideafullrefundofanymoneypaidbyauserwhonotifies youinwriting(orbye-mail)within30daysofreceiptthats/he doesnotagreetothetermsofthefullProjectGutenberg-tm License.Youmustrequiresuchausertoreturnor destroyallcopiesoftheworkspossessedinaphysicalmedium anddiscontinuealluseofandallaccesstoothercopiesof ProjectGutenberg-tmworks.\n",
            "/content/drive/MyDrive/thirdai_hack/books/The-Yellow-Wallpaper.pdf\n",
            "************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TUThFZqHwkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}