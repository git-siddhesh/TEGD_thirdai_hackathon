{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-siddhesh/TEGD_thirdai_hackathon/blob/main/Thirdai_gdrive_engine_TEGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnIfQGtUNKD9",
        "outputId": "58294a25-c6f1-4263-ed2a-28a92ce18c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Z9bciBRkbnA9"
      },
      "outputs": [],
      "source": [
        "root_directory = '/content/drive/MyDrive'\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JN8BOj1w10bB"
      },
      "outputs": [],
      "source": [
        "loc_map_dict = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZYml3a957k"
      },
      "source": [
        "## Fetch All the Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO8KjW4ubwYq",
        "outputId": "7ed25140-52a6-4853-8adc-3064e750e06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /content/drive/MyDrive\n",
            "Current directory: /content/drive/MyDrive/Dwarka (1)\n",
            "Current directory: /content/drive/MyDrive/Colab Notebooks\n",
            "Current directory: /content/drive/MyDrive/Dwarka\n",
            "Current directory: /content/drive/MyDrive/transcriptions\n",
            "Current directory: /content/drive/MyDrive/log_dir\n",
            "Current directory: /content/drive/MyDrive/log_dir/audio_csv\n"
          ]
        }
      ],
      "source": [
        "# Walk through all directories and subdirectories\n",
        "from collections import defaultdict\n",
        "\n",
        "all_files = defaultdict(list)\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
        "    print(f\"Current directory: {dirpath}\")\n",
        "\n",
        "    # List the files in the current directory\n",
        "    for filename in filenames:\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "        # print(f\"File: {file_path}\")\n",
        "        file_type = file_path.split('.')[-1]\n",
        "        all_files[file_type].append(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2K8HqTNcGWM",
        "outputId": "3943d92a-2532-44a1-8a03-b256e2af0322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['gdoc', 'docx', 'pdf', 'gslides', 'pptx', 'ipynb', 'png', '/content/drive/MyDrive/Untitled', 'gsheet', 'csv', 'xlsx', 'xls', 'mp3', 'jpg', 'mp4', 'jpeg', 'webp', '/content/drive/MyDrive/Dwarka (1)/Audio from Sai Krishna', '/content/drive/MyDrive/Dwarka/Audio from Sai Krishna', 'txt', 'wav'])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_files.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvrkrTT5ehDO",
        "outputId": "640f2e7a-794c-4de2-a855-be17a23a20d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file type: pdf has 7 files\n",
            "file type: mp3 has 2 files\n",
            "file type: docx has 11 files\n"
          ]
        }
      ],
      "source": [
        "for file_ext in ['pdf', 'mp3', 'docx']:\n",
        "    print(f\"file type: {file_ext} has {len(all_files[file_ext])} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "NGxMxLbNfjEK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO2JVKbpyzRu"
      },
      "source": [
        "### Extract the text from mp3 file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PIo7-UszbdS"
      },
      "source": [
        "#### Gather the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3s07Alh-E63",
        "outputId": "61240dcb-eb2f-47c6-e36e-6d56f6def5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to fetch and train mp3 files too?\n",
            "It will take a lot of time. You can skip it for now\n",
            "Press 'y' to extract audio files else press 'n'n\n"
          ]
        }
      ],
      "source": [
        "mp3_train = False\n",
        "print(\"Do you want to fetch and train mp3 files too?\")\n",
        "print(\"It will take a lot of time. You can skip it for now\")\n",
        "if 'y' in input(\"Press 'y' to extract audio files else press 'n'\").lower():\n",
        "  mp3_train = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTYVvn8-8ao",
        "outputId": "b3d028f8-991e-432d-e836-299a3f5b28bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mp3_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZMPQp8LylLy",
        "outputId": "1d775084-75b4-4444-9362-5b800ede4dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You need to install all the dependencies later\n"
          ]
        }
      ],
      "source": [
        "if mp3_train:\n",
        "  !git clone https://github.com/ggerganov/whisper.cpp.git\n",
        "  %cd /content/whisper.cpp/models\n",
        "  !bash download-ggml-model.sh base.en\n",
        "  %cd ..\n",
        "  !make\n",
        "  !pip install pydub\n",
        "  !apt install ffmpeg\n",
        "else:\n",
        "  print(\"You need to install all the dependencies later\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRfOGSqhhNYO"
      },
      "source": [
        "```python  \n",
        "\n",
        "!git clone https://github.com/ggerganov/whisper.cpp.git  \n",
        "%cd /content/whisper.cpp/models  \n",
        "!bash download-ggml-model.sh base.en  \n",
        "%cd ..  \n",
        "!make   \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1cCk1QrQyovz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuRey2MpzTfT"
      },
      "source": [
        "```python  \n",
        "!pip install pydub  \n",
        "!apt install ffmpeg  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af1S5cnTz05p"
      },
      "source": [
        "#### UTILS functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lGYMmq-z8wB"
      },
      "source": [
        "> Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bwhNirUIzwQs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import csv\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0p8qd-ez_1O"
      },
      "source": [
        "> mp3 -> wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yvt1xgs6z8JN"
      },
      "outputs": [],
      "source": [
        "def convert_to_wav(file_path, audio_log_dir):\n",
        "    # Split the file path into base and extension\n",
        "    base, ext = os.path.splitext(file_path)\n",
        "    # Only process files that aren't already in wav format\n",
        "    if ext.lower() != \".wav\":\n",
        "        # Load the audio file\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        # Set frame rate to 16 kHz\n",
        "        audio = audio.set_frame_rate(16000)\n",
        "        # Save as wav\n",
        "        wav_file_path = audio_log_dir + base.split('/')[-1] + \".wav\"\n",
        "        audio.export(wav_file_path, format=\"wav\")\n",
        "        print(f\"Saved as {wav_file_path}\")\n",
        "    else:\n",
        "        print(f\"File is already in wav format: {file_path}\")\n",
        "    return wav_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5wH0wJu0JO1"
      },
      "source": [
        "> wav -> text (using whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eZMQfoI90IZW"
      },
      "outputs": [],
      "source": [
        "def transcript_wav_totext_using_whisper(wav_file_path):\n",
        "    base, ext = os.path.splitext(wav_file_path)\n",
        "    command = f\"./main -f '{wav_file_path}' >  {base}.txt\"\n",
        "    print(command)\n",
        "    process = subprocess.run(command, shell=True, check=True)\n",
        "    text_file_path = f'{base}.txt'\n",
        "    return text_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1z8a81U0h7F"
      },
      "source": [
        "> text -> csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "zUzs6Zbw0T5m"
      },
      "outputs": [],
      "source": [
        "def generate_transcription_csv(text_file_path):\n",
        "    csv_file_path = text_file_path.replace('.txt', '.csv')\n",
        "    with open(text_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "        for line in txt_file:\n",
        "            line = line.strip()\n",
        "            # Skip empty lines\n",
        "            if line == '':\n",
        "                continue\n",
        "            # Split the line into timestamp and transcription\n",
        "            time_stamp, transcription = line.split(']', 1)\n",
        "            # Remove the leading '[' from the timestamp\n",
        "            time_stamp = time_stamp[1:]\n",
        "            # Remove leading and trailing spaces from the transcription\n",
        "            transcription = transcription.strip()\n",
        "            # Skip lines where the transcription is enclosed in square brackets\n",
        "            if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "                # Write the data to the CSV file\n",
        "                csv_writer.writerow([time_stamp, transcription])\n",
        "    print(f\"CSV file has been saved at: {csv_file_path}\")\n",
        "    return csv_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IszB7Gqp0pxz"
      },
      "source": [
        "#### **Final** call: mp3 -> *csv*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "r813fCy_9yoj"
      },
      "outputs": [],
      "source": [
        "def begin(file_path, audio_log_dir):\n",
        "    wav_file_path = convert_to_wav(file_path, audio_log_dir)\n",
        "    #################### Map The original path of the mp3 file to csv file ##############\n",
        "    text_file_path = transcript_wav_totext_using_whisper(wav_file_path)\n",
        "    csv_file_path = generate_transcription_csv(text_file_path)\n",
        "    loc_map_dict[csv_file_path] = file_path\n",
        "    print(f'file_path {file_path}')\n",
        "    print(f'wav_file_path {wav_file_path}')\n",
        "    print(f'text_file_path {text_file_path}\\n')\n",
        "    print(f\"File {file_path} converted to csv {text_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "oNHyn_uk0hO5"
      },
      "outputs": [],
      "source": [
        "\n",
        "if mp3_train:\n",
        "  print(root_directory)\n",
        "  os.chdir(root_directory)\n",
        "  !pwd\n",
        "  audio_log_dir = root_directory+\"/log_dir/audio_csv/\"\n",
        "  if not os.path.exists(audio_log_dir):\n",
        "      print(\"Create audio log dir\")\n",
        "      os.makedirs('log_dir/audio_csv')\n",
        "\n",
        "  else:\n",
        "      print(\"path already exist\",audio_log_dir)\n",
        "\n",
        "  os.chdir('/content/whisper.cpp/')\n",
        "  for mp3_file in all_files['mp3']:\n",
        "      begin(mp3_file, audio_log_dir)\n",
        "      break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osH7I1rHBCI7",
        "outputId": "345d93ca-87c9-4724-a858-0c0fc3de5d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loc_map_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_itp7scT_Du2"
      },
      "source": [
        "## Train Neural DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csLA1-G1_MQI"
      },
      "source": [
        "> imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URMyppf7_lmo"
      },
      "source": [
        "\n",
        "```python\n",
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2njVmxru_p4a",
        "outputId": "c9760f71-a2ab-478a-df1a-40cf2082b4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thirdai in /usr/local/lib/python3.10/dist-packages (0.7.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->thirdai) (1.16.0)\n",
            "Requirement already satisfied: thirdai[neural_db] in /usr/local/lib/python3.10/dist-packages (0.7.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.5.3)\n",
            "Requirement already satisfied: PyTrie in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (0.4.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.22.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (0.0.252)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (0.0.1)\n",
            "Requirement already satisfied: trafilatura in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.2.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (0.8.11)\n",
            "Requirement already satisfied: url-normalize in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.4.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (3.8.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.3.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.10.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2022.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->thirdai[neural_db]) (4.11.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (8.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (4.65.0)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx->thirdai[neural_db]) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from PyTrie->thirdai[neural_db]) (2.4.0)\n",
            "Requirement already satisfied: courlan>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from trafilatura->thirdai[neural_db]) (0.9.3)\n",
            "Requirement already satisfied: htmldate>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from trafilatura->thirdai[neural_db]) (1.2.3)\n",
            "Requirement already satisfied: justext>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura->thirdai[neural_db]) (3.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize->thirdai[neural_db]) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: langcodes>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.7.2->trafilatura->thirdai[neural_db]) (3.3.0)\n",
            "Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.7.2->trafilatura->thirdai[neural_db]) (0.13)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (0.9.0)\n",
            "Requirement already satisfied: dateparser>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.2.1->trafilatura->thirdai[neural_db]) (1.1.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->thirdai[neural_db]) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->thirdai[neural_db]) (2.4.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.1->htmldate>=1.2.1->trafilatura->thirdai[neural_db]) (5.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (1.0.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.252)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: paper-qa in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from paper-qa) (3.14.0)\n",
            "Requirement already satisfied: langchain>=0.0.198 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.0.252)\n",
            "Requirement already satisfied: openai>=0.27.8 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.27.8)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from paper-qa) (1.7.4)\n",
            "Requirement already satisfied: PyCryptodome in /usr/local/lib/python3.10/dist-packages (from paper-qa) (3.18.0)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.10/dist-packages (from paper-qa) (2020.1.16)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.8->paper-qa) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->paper-qa) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain>=0.0.198->paper-qa) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.198->paper-qa) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4zMGIAzf-_3A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from thirdai import licensing, neural_db as ndb\n",
        "licensing.deactivate()\n",
        "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "5W5vEbvaAMWX"
      },
      "outputs": [],
      "source": [
        "db = ndb.NeuralDB(user_id=\"siddhesh_saiKrishna\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dk1hmdUaAdFn",
        "outputId": "8e0915a6-0491-4b37-f230-6245e0032a73"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(\"/content\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "RrzB0DhLAjqo"
      },
      "outputs": [],
      "source": [
        "# Set up a cache directory\n",
        "import os\n",
        "if not os.path.isdir(\"bazaar_cache\"):\n",
        "    os.mkdir(\"bazaar_cache\")\n",
        "from pathlib import Path\n",
        "from thirdai.neural_db import Bazaar\n",
        "bazaar = Bazaar(cache_dir=Path(\"bazaar_cache\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "YAwiVxEBA0nW"
      },
      "outputs": [],
      "source": [
        "bazaar.fetch() # Optional arg filter=\"model name\" to filter by model name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc5IjrO9A3Tx",
        "outputId": "180569fd-5d42-4527-fa5c-65c48b043375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Contract Review', 'Finance QnA', 'General QnA']\n"
          ]
        }
      ],
      "source": [
        "print(bazaar.list_model_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "2yzKpUTtA7gx"
      },
      "outputs": [],
      "source": [
        "db = bazaar.get_model(\"General QnA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1kuoIuNBZvr"
      },
      "source": [
        "## Insert files to N-DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "69d6QmjWB0_t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEl3AEizB0wK",
        "outputId": "f866fe80-483c-461a-c1aa-7c49fb74785f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSqlUHb9BhvA"
      },
      "source": [
        "#### PDFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_8TJxF1BgyA",
        "outputId": "7580194d-fe3d-4692-d2ba-0081bd7eddfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Personal Statement .pdf done\n",
            "/content/drive/MyDrive/SOP.pdf done\n",
            "/content/drive/MyDrive/Introduction to Algorithms-Cormen.pdf done\n",
            "/content/drive/MyDrive/Software Engineering Rajib Mall.pdf done\n",
            "/content/drive/MyDrive/UnderstandingDeepLearning_03_05_23_C.pdf done\n",
            "/content/drive/MyDrive/Resume_2023.pdf done\n",
            "/content/drive/MyDrive/DOC-20230804-WA0021.pdf done\n"
          ]
        }
      ],
      "source": [
        "insertable_docs = []\n",
        "pdf_files = all_files['pdf']\n",
        "\n",
        "for file in pdf_files:\n",
        "    try:\n",
        "        pdf_doc = ndb.PDF(file)\n",
        "        insertable_docs.append(pdf_doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCF_Ae5vINQ4"
      },
      "source": [
        "#### docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvuAU4NDj-v",
        "outputId": "afca103b-8c91-49c2-b889-80ec51dfb144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/22210036_FP602 (1).docx done\n",
            "/content/drive/MyDrive/22210036_FP602.docx done\n",
            "/content/drive/MyDrive/22210036_Assignment2.docx done\n",
            "/content/drive/MyDrive/Abstract_22210036 (1).docx done\n",
            "/content/drive/MyDrive/Abstract_22210036.docx done\n",
            "/content/drive/MyDrive/sai krishna resume.docx done\n",
            "/content/drive/MyDrive/LOR-Yashwanth(Chalapathi Rao) (1).docx done\n",
            "/content/drive/MyDrive/LOR-Yashwanth(Chalapathi Rao).docx done\n",
            "/content/drive/MyDrive/A.Y. 2021-2022.docx done\n",
            "/content/drive/MyDrive/Doc1.docx done\n",
            "/content/drive/MyDrive/Resume_2023.docx done\n"
          ]
        }
      ],
      "source": [
        "doc_files = all_files['docx']\n",
        "\n",
        "for file in doc_files:\n",
        "    try:\n",
        "        doc = ndb.DOCX(file)\n",
        "        insertable_docs.append(doc)\n",
        "        print(f'{file} done')\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L3DAwre73Tw2",
        "outputId": "458893f5-a84b-4dc3-9478-080fb8b4c094"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/log_dir/audio_csv/'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loc_map_dict.keys()\n",
        "audio_log_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akUqXpxfIPVd"
      },
      "source": [
        "#### music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jy9KBbg30ip",
        "outputId": "5048e95b-3813-4f2b-b485-2c39c2531341"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/log_dir/audio_csv/roadtoOz_24_baum_64kb.csv']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_files = [audio_log_dir+file for file in os.listdir(audio_log_dir) if file.endswith('.csv')]\n",
        "audio_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "zZWEnclx49uV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file\n",
        "for file in audio_files:\n",
        "    df = pd.read_csv(file)\n",
        "    # Add the new column with values from 0 to n-1\n",
        "    df['DOC_ID'] = range(len(df))\n",
        "    # Save the updated DataFrame back to the CSV file\n",
        "    df.to_csv(file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Y28oJk8C5m-i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "gE2kknBQIKS5"
      },
      "outputs": [],
      "source": [
        "if mp3_train:\n",
        "  for file in audio_files:\n",
        "      try:\n",
        "        csv_doc = ndb.CSV(\n",
        "            path=file,\n",
        "            id_column=\"DOC_ID\",\n",
        "            strong_columns=[\"transcription\"],\n",
        "            weak_columns=[\"time_stamp\"],\n",
        "            reference_columns=[\"time_stamp\"])\n",
        "        insertable_docs.append(csv_doc)\n",
        "      except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YrCU3zgISNV"
      },
      "source": [
        "### Insert into database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "jKR1bvMOFAhj"
      },
      "outputs": [],
      "source": [
        "source_ids = db.insert(insertable_docs, train=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPa1lItJGKkc"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cxiq3CmGLkj",
        "outputId": "0cc0c809-d990-4f96-9e44-6cd6f351b729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter prompt: sai krishna avula\n",
            "Best, Sai Krishna\n",
            "/content/drive/MyDrive/22210036_FP602 (1).docx\n",
            "************\n",
            "Best, Sai Krishna\n",
            "/content/drive/MyDrive/22210036_FP602.docx\n",
            "************\n",
            "(C) MIT Press. B.4 Special types of matrix 445 to the origin when the matrix is applied. Determinants of matrix expressions obey the following rules: |AT | = |A| |AB| = |A||B| |A-1| = 1/|A|. (B.14) The trace of a square matrix is the sum of the diagonal values (the matrix itself need not be diagonal) or the sum of the eigenvalues.\n",
            "/content/drive/MyDrive/UnderstandingDeepLearning_03_05_23_C.pdf\n",
            "************\n"
          ]
        }
      ],
      "source": [
        "query = input(\"Enter prompt: \")\n",
        "search_results = db.search(\n",
        "    # query=\"what is the termination period\",\n",
        "    query=query,\n",
        "    top_k=3,\n",
        "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
        "\n",
        "for result in search_results:\n",
        "    print(result.text)\n",
        "    # print(result.context(radius=1))\n",
        "    if loc_map_dict.get(result.source, None) == None:\n",
        "        print(result.source)\n",
        "    else:\n",
        "        print(loc_map_dict.get(result.source, None))\n",
        "    # print(result.metadata)\n",
        "    print('************')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "1TUThFZqHwkh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
